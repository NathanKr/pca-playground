<h2>experiment with PCA which is according to Andrew Ng "This is by far the most common algorithm for dimensionality reduction"</h2>

<h2>Content</h2>
<table>
  <tr>
    <th>File</th>
    <th>Description</th>
  </tr>
  <tr>
    <td>pca1.py</td>
    <td>
    <ul>
    <li>Use SVD to compute variance retained in PCA</li>
    <li>Here we have 2 features which are linear correlated thus using 1 PCA components retains about 87% of the variance</li>
    <li>Use StandardScaler to pre process the features by means of mean and scaling</li>
    <li>The dataset is from Andrew Ng Coursera course</li>
    </ul>
    </ul>
    </td>
  </tr>
  <tr>
    <td>pca_boston_houses.py</td>
    <td>
    <ul>
    <li>Use SVD to compute variance retained in PCA</li>
    <li>Here we have 13 features and variance retained is shown on fig1</li>
    <li>Use StandardScaler to pre process the features by means of mean and scaling</li>
    </ul>
    </ul>
    </td>
  </tr>
</table>
